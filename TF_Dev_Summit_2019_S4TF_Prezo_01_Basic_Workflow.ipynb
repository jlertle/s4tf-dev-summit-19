{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Dev Summit - 2019 - S4TF Prezo - 01 Basic Workflow",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "kZRlD4utdPuX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import TensorFlow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yuk5YqDAjI7k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modifying machine learning models\n"
      ]
    },
    {
      "metadata": {
        "id": "VoWRtV0ujokr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "struct Model: Layer {\n",
        "  // TODO: Make me skip connection!\n",
        "  var conv = Conv2D<Float>(filterShape: (5, 5, 3, 6))\n",
        "  var maxpool = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "  @noDerivative var flatten = Flatten<Float>()\n",
        "  var dense = Dense<Float>(inputSize: 36 * 6, outputSize: 10)\n",
        "\n",
        "  @differentiable\n",
        "  func applied(to input: Tensor<Float>, in context: Context) -> Tensor<Float> {\n",
        "    return input.sequenced(in: context,\n",
        "                           through: conv, maxpool, flatten, dense)\n",
        "  }\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5O-5kCEniSpJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "// Use random training data.\n",
        "let images = Tensor<Float>(randomNormal: [10, 16, 16, 3])\n",
        "let labels = Tensor<Int32>(rangeFrom: 0, to: 10, stride: 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x44kFjA0tRFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "var model = Model()\n",
        "let opt = SGD(for: model, scalarType: Float.self)\n",
        "let context = Context(learningPhase: .training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mMxjNQIDtxgR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in 0..<10 {\n",
        "  print(\"Starting training step \\(i)\")\n",
        "  let (loss, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "    let logits = model.applied(to: images, in: context)\n",
        "    return softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "  }\n",
        "  print(\"Loss: \\(loss)\")\n",
        "  opt.update(&model.allDifferentiableVariables, along: gradients)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fj2p7hI9irot",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Writing & debugging custom layers\n"
      ]
    },
    {
      "metadata": {
        "id": "-kkzkXoTIfaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "// A custom layer type that's similar to a Dense layer, but with an extra bias\n",
        "// term.\n",
        "struct DoubleBiasDense: Layer {\n",
        "  // TODO(saeta): FILL ME IN!\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cCPK6TGCmv6m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "struct Model2: Layer {\n",
        "  var conv = Conv2D<Float>(filterShape: (5, 5, 3, 6))\n",
        "  var maxpool = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "  var flatten = Flatten<Float>()\n",
        "  var dense = DoubleBiasDense(inputSize: 36 * 6, outputSize: 10)\n",
        "\n",
        "  @differentiable\n",
        "  func applied(to input: Tensor<Float>, in context: Context) -> Tensor<Float> {\n",
        "    return input.sequenced(in: context,\n",
        "                           through: conv, maxpool, flatten, dense)\n",
        "  }\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lBHoMwoesa_f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "var model = Model2()\n",
        "let opt = SGD(for: model, scalarType: Float.self)\n",
        "\n",
        "for i in 0..<10 {\n",
        "  print(\"Starting training step \\(i)\")\n",
        "  let (loss, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "    let logits = model.applied(to: images, in: context)\n",
        "    return softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "  }\n",
        "  print(\"Loss: \\(loss)\")\n",
        "  opt.update(&model.allDifferentiableVariables, along: gradients)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vfqUcfPHjzLv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experimenting with batch sizes and gradients\n"
      ]
    },
    {
      "metadata": {
        "id": "JliPTFbSDHS-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in 0..<10 {\n",
        "  print(\"Starting training step \\(i)\")\n",
        "  var grads = Model2.AllDifferentiableVariables.zero\n",
        "  for j in 0..<4 {\n",
        "    print(\"Starting sub-step \\(j)\")\n",
        "    let stepGrad = gradient(at: model) { model -> Tensor<Float> in\n",
        "      let logits = model.applied(to: images, in: context)\n",
        "      return softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "    }\n",
        "    grads += stepGrad\n",
        "  }\n",
        "  opt.update(&model.allDifferentiableVariables, along: grads)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iv7BGxjkFb9C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}